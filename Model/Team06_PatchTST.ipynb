{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PA_-skk1X3E",
        "outputId": "4e5f8acb-a8cb-44b4-9315-00c01492b0ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/IBM/tsfm.git\n",
            "  Cloning https://github.com/IBM/tsfm.git to /tmp/pip-req-build-y8qinsmv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/IBM/tsfm.git /tmp/pip-req-build-y8qinsmv\n",
            "  Resolved https://github.com/IBM/tsfm.git to commit 02dc9dc7e672abfc3ec6d421deedaff696de81ad\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas>=2.2.0 (from tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from tsfm_public==0.1.1.dev3+g02dc9dc) (1.2.2)\n",
            "Requirement already satisfied: transformers[torch]>=4.36.1 in /usr/local/lib/python3.10/dist-packages (from tsfm_public==0.1.1.dev3+g02dc9dc) (4.41.1)\n",
            "Collecting datasets (from tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->tsfm_public==0.1.1.dev3+g02dc9dc) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->tsfm_public==0.1.1.dev3+g02dc9dc) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->tsfm_public==0.1.1.dev3+g02dc9dc) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->tsfm_public==0.1.1.dev3+g02dc9dc) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (0.23.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (3.9.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->tsfm_public==0.1.1.dev3+g02dc9dc) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->tsfm_public==0.1.1.dev3+g02dc9dc) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->tsfm_public==0.1.1.dev3+g02dc9dc) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->tsfm_public==0.1.1.dev3+g02dc9dc) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->tsfm_public==0.1.1.dev3+g02dc9dc) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]>=4.36.1->tsfm_public==0.1.1.dev3+g02dc9dc) (1.3.0)\n",
            "Building wheels for collected packages: tsfm_public\n",
            "  Building wheel for tsfm_public (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tsfm_public: filename=tsfm_public-0.1.1.dev3+g02dc9dc-py3-none-any.whl size=2302229 sha256=cc625057e173884462ff1c58ef233f0a8967ed8b32b91111c9416923a45c83b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zm6iyhx7/wheels/5a/6f/47/d5b39e2ef02fcf2babe83b47c59d429538120556b0bde4cb43\n",
            "Successfully built tsfm_public\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, accelerate, tsfm_public\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.30.1 datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pandas-2.2.2 tsfm_public-0.1.1.dev3+g02dc9dc xxhash-3.4.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/IBM/tsfm.git\n",
        "!pip install transformers pandas scikit-learn matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vG8_30a1d7P",
        "outputId": "2cf1ed19-398c-4f9f-d5de-3b96ce4dc167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nr6BzBGS1i4H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_squared_log_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import PatchTSTConfig, PatchTSTForPrediction, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
        "from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n",
        "from tsfm_public.toolkit.util import select_by_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qroJHt_l-31E"
      },
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "# Set seed for reproducibility\n",
        "set_seed(2023)\n",
        "\n",
        "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
        "data = pd.read_csv('/content/gold_price_2018_2024.csv')\n",
        "\n",
        "# Chuy·ªÉn ƒë·ªïi c·ªôt Date th√†nh ƒë·ªãnh d·∫°ng datetime\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "timestamp_column = 'Date'\n",
        "forecast_columns = ['Value (USD per troy ounce)']\n",
        "\n",
        "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra theo t·ª∑ l·ªá 7-3\n",
        "train_size = int(len(data) * 0.7)\n",
        "test_size = len(data) - train_size\n",
        "train, test = train_test_split(data, test_size=test_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sm3rx90BLNaE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define parameters\n",
        "context_length = 512\n",
        "forecast_horizon = 96\n",
        "patch_length = 16\n",
        "num_workers = 4\n",
        "batch_size = 64\n",
        "\n",
        "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra theo t·ª∑ l·ªá 7-3\n",
        "train_size = int(len(data) * 0.7)\n",
        "test_size = len(data) - train_size\n",
        "train, test = train_test_split(data, test_size=test_size, shuffle=False)\n",
        "\n",
        "# Chu·∫©n b·ªã d·ªØ li·ªáu\n",
        "time_series_preprocessor = TimeSeriesPreprocessor(\n",
        "    timestamp_column=timestamp_column,\n",
        "    id_columns=[],\n",
        "    input_columns=forecast_columns,\n",
        "    output_columns=forecast_columns,\n",
        "    scaling=True,\n",
        ")\n",
        "\n",
        "train_data = select_by_index(train, start_index=0, end_index=len(train))\n",
        "test_data = select_by_index(test, start_index=0, end_index=len(test))\n",
        "\n",
        "time_series_preprocessor = time_series_preprocessor.train(train_data)\n",
        "\n",
        "train_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(train_data),\n",
        "    id_columns=[],\n",
        "    timestamp_column=timestamp_column,\n",
        "    target_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")\n",
        "\n",
        "test_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(test_data),\n",
        "    id_columns=[],\n",
        "    timestamp_column=timestamp_column,\n",
        "    target_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdEqlNTBPyKy",
        "outputId": "95660394-44de-4dc4-db1f-5d27687911a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(data: pandas.core.frame.DataFrame, id_columns: List[str] = [], timestamp_column: Optional[str] = None, target_columns: List[str] = [], observable_columns: List[str] = [], control_columns: List[str] = [], conditional_columns: List[str] = [], static_categorical_columns: List[str] = [], context_length: int = 1, prediction_length: int = 1, num_workers: int = 1, frequency_token: Optional[int] = None, autoregressive_modeling: bool = True)\n"
          ]
        }
      ],
      "source": [
        "# Inspect the signature of the ForecastDFDataset class\n",
        "import inspect\n",
        "print(inspect.signature(ForecastDFDataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T2IUK7RsRBrQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# C·∫•u h√¨nh m√¥ h√¨nh PatchTST\n",
        "config = PatchTSTConfig(\n",
        "    num_input_channels=len(forecast_columns),\n",
        "    context_length=context_length,\n",
        "    patch_length=patch_length,\n",
        "    patch_stride=patch_length,\n",
        "    prediction_length=forecast_horizon,\n",
        "    random_mask_ratio=0.4,\n",
        "    d_model=128,\n",
        "    num_attention_heads=16,\n",
        "    num_hidden_layers=3,\n",
        "    ffn_dim=256,\n",
        "    dropout=0.2,\n",
        "    head_dropout=0.2,\n",
        "    pooling_type=None,\n",
        "    channel_attention=False,\n",
        "    scaling=\"std\",\n",
        "    loss=\"mse\",\n",
        "    pre_norm=True,\n",
        "    norm_type=\"batchnorm\",\n",
        ")\n",
        "\n",
        "model = PatchTSTForPrediction(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br9rm3zvRFRk"
      },
      "source": [
        "Train model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "QUk9_XGLRF2v",
        "outputId": "2142fac5-e784-4e3e-9e95-add21a4a0a6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  15/1600 00:00 < 00:29, 54.39 it/s, Epoch 0.88/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.338300</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'eval_loss'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7502d12c575b>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2732\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmetric_to_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m                 \u001b[0mmetric_to_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"eval_{metric_to_check}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m             \u001b[0mmetric_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_to_check\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m             \u001b[0moperator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater_is_better\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'eval_loss'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# H√†m t√≠nh to√°n c√°c ch·ªâ s·ªë ƒë√°nh gi√°\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    mse = mean_squared_error(labels, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mape = mean_absolute_percentage_error(labels, predictions)\n",
        "    return {\n",
        "        'eval_loss': mse,\n",
        "        'rmse': rmse,\n",
        "        'mape': mape\n",
        "    }\n",
        "\n",
        "# Thi·∫øt l·∫≠p c√°c tham s·ªë hu·∫•n luy·ªán\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoint/patchtst/gold_price/output/\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=100,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    dataloader_num_workers=num_workers,\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    logging_dir=\"./checkpoint/patchtst/gold_price/logs/\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStoppingCallback(\n",
        "    early_stopping_patience=10,\n",
        "    early_stopping_threshold=0.0001,\n",
        ")\n",
        "\n",
        "# Hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,  # S·ª≠ d·ª•ng t·∫≠p ki·ªÉm tra l√†m t·∫≠p ƒë√°nh gi√°\n",
        "    # compute_metrics=compute_metrics,\n",
        "    callbacks=[early_stopping_callback],\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra\n",
        "results = trainer.evaluate(test_dataset)\n",
        "print(\"Test results:\", results)\n",
        "\n",
        "# H√†m v·∫Ω bi·ªÉu ƒë·ªì k·∫øt qu·∫£\n",
        "def plot_results(dates, actual, train, predict, title):\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.plot(dates, actual, label='Actual Price', color='red')\n",
        "    plt.plot(dates[:len(train)], train, label='Train Price', color='green')\n",
        "    plt.plot(dates[len(train):len(train)+len(predict)], predict, label='Predicted Price', color='blue')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Price (USD)')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# V·∫Ω bi·ªÉu ƒë·ªì k·∫øt qu·∫£\n",
        "predicted_values = model.predict(test_dataset)\n",
        "plot_results(data['Date'], data['Value (USD per troy ounce)'], train['Value (USD per troy ounce)'], predicted_values, 'Gold Price Prediction')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "mRUFRgcqteXS",
        "outputId": "e88f46e0-d3d0-4240-dd44-6c705576f908"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test result:\n",
            "{'eval_loss': 0.06905169785022736, 'eval_runtime': 0.6211, 'eval_samples_per_second': 1.61, 'eval_steps_per_second': 1.61, 'epoch': 16.0}\n"
          ]
        }
      ],
      "source": [
        "results = trainer.evaluate(test_dataset)\n",
        "print(\"Test result:\")\n",
        "print(results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "Vlavv8VdDwEo",
        "outputId": "468f9daf-5bc4-48b3-d7e9-be80cbaf5ca9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  16/1600 00:00 < 01:15, 20.91 it/s, Epoch 0.94/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.611600</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'eval_loss'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-aa9b872fc7f7>\u001b[0m in \u001b[0;36m<cell line: 147>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;31m# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2732\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmetric_to_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m                 \u001b[0mmetric_to_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"eval_{metric_to_check}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m             \u001b[0mmetric_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_to_check\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m             \u001b[0moperator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater_is_better\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'eval_loss'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import PatchTSTConfig, PatchTSTForPrediction, Trainer, TrainingArguments, EarlyStoppingCallback, DefaultDataCollator\n",
        "from tsfm_public.toolkit.dataset import ForecastDFDataset\n",
        "from tsfm_public.toolkit.time_series_preprocessor import TimeSeriesPreprocessor\n",
        "from tsfm_public.toolkit.util import select_by_index\n",
        "\n",
        "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
        "data = pd.read_csv('/content/gold_price_2018_2024.csv')\n",
        "\n",
        "# Chuy·ªÉn ƒë·ªïi c·ªôt Date th√†nh ƒë·ªãnh d·∫°ng datetime\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "timestamp_column = 'Date'\n",
        "forecast_columns = ['Value (USD per troy ounce)']\n",
        "\n",
        "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra theo t·ª∑ l·ªá 7-3\n",
        "train_size = int(len(data) * 0.7)\n",
        "test_size = len(data) - train_size\n",
        "train, test = train_test_split(data, test_size=test_size, shuffle=False)\n",
        "\n",
        "# Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√†nh ƒë·ªãnh d·∫°ng th√≠ch h·ª£p cho m√¥ h√¨nh PatchTST\n",
        "context_length = 512\n",
        "forecast_horizon = 96\n",
        "patch_length = 16\n",
        "num_workers = 4\n",
        "batch_size = 64\n",
        "\n",
        "# Chu·∫©n b·ªã d·ªØ li·ªáu\n",
        "time_series_preprocessor = TimeSeriesPreprocessor(\n",
        "    timestamp_column=timestamp_column,\n",
        "    id_columns=[],\n",
        "    input_columns=forecast_columns,\n",
        "    output_columns=forecast_columns,\n",
        "    scaling=True,\n",
        ")\n",
        "\n",
        "train_data = select_by_index(train, start_index=0, end_index=len(train))\n",
        "test_data = select_by_index(test, start_index=0, end_index=len(test))\n",
        "\n",
        "time_series_preprocessor = time_series_preprocessor.train(train_data)\n",
        "\n",
        "train_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(train_data),\n",
        "    id_columns=[],\n",
        "    timestamp_column=timestamp_column,\n",
        "    target_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")\n",
        "\n",
        "test_dataset = ForecastDFDataset(\n",
        "    time_series_preprocessor.preprocess(test_data),\n",
        "    id_columns=[],\n",
        "    timestamp_column=timestamp_column,\n",
        "    target_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")\n",
        "\n",
        "# C·∫•u h√¨nh m√¥ h√¨nh PatchTST\n",
        "config = PatchTSTConfig(\n",
        "    num_input_channels=len(forecast_columns),\n",
        "    context_length=context_length,\n",
        "    patch_length=patch_length,\n",
        "    patch_stride=patch_length,\n",
        "    prediction_length=forecast_horizon,\n",
        "    random_mask_ratio=0.4,\n",
        "    d_model=128,\n",
        "    num_attention_heads=16,\n",
        "    num_hidden_layers=3,\n",
        "    ffn_dim=256,\n",
        "    dropout=0.2,\n",
        "    head_dropout=0.2,\n",
        "    pooling_type=None,\n",
        "    channel_attention=False,\n",
        "    scaling=\"std\",\n",
        "    loss=\"mse\",\n",
        "    pre_norm=True,\n",
        "    norm_type=\"batchnorm\",\n",
        ")\n",
        "\n",
        "model = PatchTSTForPrediction(config)\n",
        "\n",
        "# H√†m t√≠nh to√°n c√°c ch·ªâ s·ªë ƒë√°nh gi√°\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "    predictions = predictions.reshape(-1, len(forecast_columns))\n",
        "    labels = labels.reshape(-1, len(forecast_columns))\n",
        "    mse = mean_squared_error(labels, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mape = mean_absolute_percentage_error(labels, predictions)\n",
        "    return {\n",
        "        'eval_loss': mse,\n",
        "        'rmse': rmse,\n",
        "        'mape': mape\n",
        "    }\n",
        "\n",
        "# Custom data collator\n",
        "class CustomDataCollator(DefaultDataCollator):\n",
        "    def __call__(self, features):\n",
        "        batch = super().__call__(features)\n",
        "        if \"labels\" in batch:\n",
        "            batch[\"labels\"] = batch[\"labels\"].view(-1, len(forecast_columns))\n",
        "        return batch\n",
        "\n",
        "data_collator = CustomDataCollator()\n",
        "\n",
        "# Thi·∫øt l·∫≠p c√°c tham s·ªë hu·∫•n luy·ªán\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoint/patchtst/gold_price/output/\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=100,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    dataloader_num_workers=num_workers,\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    logging_dir=\"./checkpoint/patchtst/gold_price/logs/\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    label_names=[\"labels\"],\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStoppingCallback(\n",
        "    early_stopping_patience=10,\n",
        "    early_stopping_threshold=0.0001,\n",
        ")\n",
        "\n",
        "# Hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[early_stopping_callback],\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra\n",
        "results = trainer.evaluate(test_dataset)\n",
        "print(\"Test results:\", results)\n",
        "\n",
        "# H√†m v·∫Ω bi·ªÉu ƒë·ªì k·∫øt qu·∫£\n",
        "def plot_results(dates, actual, train, predict, title):\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.plot(dates, actual, label='Actual Price', color='red')\n",
        "    plt.plot(dates[:len(train)], train, label='Train Price', color='green')\n",
        "    plt.plot(dates[len(train):len(train)+len(predict)], predict, label='Predicted Price', color='blue')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Price (USD)')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# V·∫Ω bi·ªÉu ƒë·ªì k·∫øt qu·∫£\n",
        "predicted_values = model.predict(test_dataset)\n",
        "plot_results(data['Date'], data['Value (USD per troy ounce)'], train['Value (USD per troy ounce)'], predicted_values, 'Gold Price Prediction')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTwKqgAgtzX6"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "save_dir = \"patchtst/gold_price/model/pretrain/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "trainer.save_model(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUPLywImvpyA"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "dataset_path = '/content/gold_price_2018_2024.csv'\n",
        "data = pd.read_csv(dataset_path, parse_dates=['Date'])\n",
        "\n",
        "# Redefine parameters\n",
        "timestamp_column = 'Date'\n",
        "forecast_columns = ['Value (USD per troy ounce)']\n",
        "context_length = 512\n",
        "forecast_horizon = 96\n",
        "\n",
        "# Split data into train and test sets (70% train, 30% test)\n",
        "num_train = int(len(data) * 0.7)\n",
        "test_start_index = num_train\n",
        "test_end_index = len(data) - context_length\n",
        "\n",
        "train_data = select_by_index(data, id_columns=[], start_index=0, end_index=num_train - context_length)\n",
        "test_data = select_by_index(data, id_columns=[], start_index=test_start_index, end_index=test_end_index)\n",
        "\n",
        "# Preprocess the data\n",
        "time_series_preprocessor = TimeSeriesPreprocessor(\n",
        "    timestamp_column=timestamp_column,\n",
        "    id_columns=[],\n",
        "    input_columns=forecast_columns,\n",
        "    output_columns=forecast_columns,\n",
        "    scaling=True,\n",
        ")\n",
        "\n",
        "# Train the scaler on the training data\n",
        "time_series_preprocessor = time_series_preprocessor.train(train_data)\n",
        "\n",
        "# Preprocess the test data\n",
        "test_data_preprocessed = time_series_preprocessor.preprocess(test_data)\n",
        "\n",
        "# Create ForecastDFDataset for test data\n",
        "test_dataset = ForecastDFDataset(\n",
        "    test_data_preprocessed,\n",
        "    id_columns=[],\n",
        "    timestamp_column=timestamp_column,\n",
        "    target_columns=forecast_columns,\n",
        "    context_length=context_length,\n",
        "    prediction_length=forecast_horizon,\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
